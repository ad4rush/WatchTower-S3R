# WatchTower S3R SecurityVision: Real-Time Video Anomaly Detection

## Overview

SecurityVision is an automated surveillance system designed for real-time video anomaly detection. It leverages advanced deep learning techniques, specifically utilizing I3D features combined with a modified Self-Supervised Sparse Representation (S3R) model, referred to as WatchTower. The system processes video input from CCTV cameras or uploaded files, identifies anomalous segments by detecting deviations from learned normal patterns, and presents alerts and visualizations through a web-based dashboard. This project aims to address the need for automated systems capable of detecting unusual or threatening activities in the vast amount of video data generated by surveillance cameras.

## Features

-   **Real-time Anomaly Detection**: Utilizes the WatchTower (S3R-based) model trained on datasets like UCF-Crime to identify anomalies.
-   **Live Video Monitoring**: Supports live video feeds with browser-based camera access.
-   **Toggle Surveillance**: Functionality to pause and resume monitoring.
-   **Visual and Audio Alerts**: Triggers alerts when anomalies are detected above a set threshold (e.g., 0.6).
-   **Backward Timer Replay**: Allows review of the video segment leading up to a detected anomaly (e.g., 16 seconds prior).
-   **Database Storage**: Saves detected anomalies with timestamps and confidence scores for future reference.
-   **Web-Based Interface**: An intuitive dashboard built with HTML, CSS (Bootstrap), and JavaScript for monitoring, visualization, and alert management.
-   **Anomaly Scoring**: Provides frame-wise ROC-AUC scores as a primary metric for evaluation.

## Technology Stack

-   **Backend**: Python with Flask framework.
-   **Machine Learning**: PyTorch for model implementation and inference (torch 1.6.0, torchvision), OpenCV for video processing.
-   **Database**: PostgreSQL (or SQLite as a fallback).
-   **Frontend**: JavaScript, HTML5, Bootstrap.
-   **Audio**: Tone.js for alert sounds.

## Theoretical Background

The anomaly detection core of this system is based on the **Self-Supervised Sparse Representation (S3R)** framework.
The S3R model operates on the principle of dictionary learning. It learns a dictionary of "normal" event patterns from a training dataset (e.g., normal videos from UCF-Crime). Anomalies are then identified as events that cannot be sparsely reconstructed using this learned dictionary.

Key components of the WatchTower (S3R based) model include:
-   **Feature Extraction**: Employs pre-trained Inflated 3D ConvNet (I3D) models (e.g., with ResNet-50 backbones) to extract robust spatiotemporal features (2048 dimensions) from video segments.
-   **Task-Specific Dictionary**: A dictionary learned from normal video features using Orthogonal Matching Pursuit (OMP). The project uses a dictionary file like 'ucf-crime_dictionaries.taskaware.omp.100iters.50pct.npy'.
-   **enNormal Module**: Reconstructs the normal component of an input feature snippet using the learned dictionary.
-   **deNormal Module**: Aims to filter out normal components, potentially highlighting anomalous parts.
-   **Anomaly Scoring**: Features are passed through embedding layers and classifiers to produce a final anomaly score.

The model checkpoint used is typically one like 'ucf-crime_s3r_i3d_best.pth', trained specifically for the UCF-Crime dataset using I3D features.

## Project Structure
.
├── ml_models/            # Machine learning model implementations
│   ├── __init__.py      
│   └── s3r_model.py      # WatchTower (S3R) model implementation
├── static/               # Static files (JS, CSS, images, sounds)
│   ├── css/
│   │   └── custom.css   
│   ├── js/
│   │   ├── anomaly-display.js
│   │   ├── main.js        
│   │   └── video-buffer.js
│   └── sounds/           # Directory for alert sounds (if any)
├── templates/            # HTML templates
│   ├── home.html        
│   ├── layout.html      
│   └── surveillance.html
├── dictionary/           # Dictionary files for WatchTower model (e.g., ucf-crime_dictionaries.taskaware.omp.100iters.50pct.npy)
├── checkpoint/           # Model checkpoint files (e.g., ucf-crime_s3r_i3d_best.pth)
├── app.py                # Flask application setup
├── main.py               # Entry point for the application
├── ml_model.py           # ML model wrapper, anomaly detection logic, thresholding
├── models.py             # Database models (SQLAlchemy)
├── routes.py             # Application routes
├── utils.py              # Utility functions
├── video_processor.py    # Video processing utilities
├── create_dictionary.py  # Script to create dictionary files (if applicable)
├── requirements.txt      # Project dependencies
├── README.md             # This file
└── USAGE.md              # Instructions on how to use the application


## Datasets

The system is designed to work with datasets like:
-   **UCF-Crime**: A large-scale dataset with long, untrimmed surveillance videos featuring 13 real-world anomalies (e.g., Fighting, Assault, Burglary) and normal activities. Standard training/testing splits and I3D features provided with the S3R methodology are used.

## Installation and Setup

1.  **Clone the repository**:
    ```bash
    git clone [https://github.com/kv-248/SecurityVision.git](https://github.com/kv-248/SecurityVision.git)
    cd SecurityVision
    ```
2.  **Create a Python virtual environment** (recommended):
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows use `venv\Scripts\activate`
    ```
3.  **Install dependencies**:
    The `requirements.txt` file lists primary dependencies. The original S3R model has its own `requirements.txt` as well.
    ```bash
    pip install -r requirements.txt
    # If using specific S3R functionalities, you might need to check S3R/requirements.txt
    ```
    Key dependencies include: Flask, SQLAlchemy, PyTorch, Torchvision, OpenCV-Python, NumPy.

4.  **Set up the Database**:
    -   The application can use PostgreSQL or fallback to SQLite.
    -   For PostgreSQL, ensure it's running, create a database, and set the `DATABASE_URL` environment variable.
    -   If `DATABASE_URL` is not set, it defaults to a local SQLite database (`surveillance.db`).
    ```bash
    # Example for setting DATABASE_URL (Linux/macOS)
    export DATABASE_URL="postgresql://user:password@host:port/database"
    ```
5.  **Download Pre-trained Models and Dictionaries**:
    -   Place the I3D model (e.g., `i3d_r50_kinetics.pth`) in an appropriate directory.
    -   Place the WatchTower/S3R checkpoint (e.g., `ucf-crime_s3r_i3d_best.pth`) in the `checkpoint/` directory.
    -   Place the task-aware dictionary (e.g., `ucf-crime_dictionaries.taskaware.omp.100iters.50pct.npy`) in the `dictionary/` directory.
    *(Links to these specific files might need to be provided or instructions on how to obtain them from the S3R repository)*

6.  **Run the application**:
    ```bash
    python main.py
    ```
    The application will be accessible at `http://localhost:5000` or `http://0.0.0.0:5000`.

## Usage

1.  **Navigate to the application** in your web browser.
2.  The **Home Page** provides an overview, system uptime, and statistics.
3.  Go to the **Surveillance Page** to start monitoring:
    * Allow camera access when prompted by the browser.
    * The video feed will start automatically.
    * Use "Toggle Surveillance" to pause/resume.
4.  **Anomaly Detection**:
    * The system processes video frames and flags anomalies.
    * Alerts (visual and audio) are triggered.
    * A replay feature shows the segment leading to the alert.
5.  **Alarm Controls**: Reset alarms as needed.
6.  **Confidence Scores**: Anomalies are reported with confidence scores. A typical detection threshold is 0.6, adjustable in `ml_model.py`.
7.  **Frame Processing**: The system may process every Nth frame (e.g., 30th) for performance, adjustable in `ml_model.py`.

*(For more detailed usage, refer to USAGE.md)*

## Performance

-   The underlying S3R model with I3D features reports a frame-level AUC of **85.99%** on the UCF-Crime dataset. The WatchTower model aims to replicate or build upon this.
-   Real-time performance is dependent on hardware (GPU acceleration is beneficial), feature extraction speed, and model inference time.

## Compute Requirements

-   **Training**: Requires GPUs (e.g., NVIDIA RTX series like RTX 2080 Ti) with sufficient memory, especially for large datasets. CUDA 10.1 was used in the reference S3R implementation.
-   **Inference**: GPU acceleration is highly recommended for real-time performance. CPU inference is possible but significantly slower.
-   **Memory/Storage**: Adequate RAM and fast storage (SSDs) are needed for video streams and features.
-   **Software Environment**: Python (3.6 tested for S3R, project report mentions 3.6), PyTorch (1.6.0 tested).

## Future Work

Based on the "SecurityVision" project report:
1.  **Explore more efficient feature extractors**: Alternatives to the computationally heavy I3D, such as MobileViT, could improve performance/cost trade-offs, especially for edge devices.
2.  **Implement online learning**: Allow the model to adapt to specific deployment environments and evolving normal patterns over time by moving from an offline dictionary to online/continual learning approaches.
3.  **Multi-camera support**: Utilize synchronized feeds from multiple cameras using multi-view learning techniques to provide richer context, handle occlusions better, and increase detection robustness.
## Acknowledgments

-   The S3R model architecture and methodology by Jhih-Ciang Wu, He-Yen Hsieh, Ding-Jie Chen, Chiou-Shann Fuh, and Tyng-Luh Liu. (Paper: "Self-Supervised Sparse Representation for Video Anomaly Detection", ECCV 2022).
-   The original S3R implementation is acknowledged as a base for some code aspects.
-   UCF-Crime dataset by the University of Central Florida.
-   I3D model by Carreira and Zisserman.

## References

-   [1] Carreira, J., & Zisserman, A. (2017). Quo vadis, action recognition? a new model and the kinetics dataset. *CVPR*.
-   [2] Sultani, W., Chen, C., & Shah, M. (2018). Real-world anomaly detection in surveillance videos. *CVPR*.
-   [3] Wang, S., Li, B. Z., Khabsa, M., Fang, H., & Ma, H. (2020). Linformer: Self-attention with linear complexity. *arXiv:2006.04768*.
-   [4] Wu, J. C., Hsieh, H. Y., Chen, D. J., Fuh, C. S., & Liu, T. L. (2022). Self-Supervised Sparse Representation for Video Anomaly Detection. *ECCV*.
-   [6] Feichtenhofer, C., Fan, H., Malik, J., & He, K. (2019). Slowfast networks for video recognition. *ICCV*.
-   [7] Mehta, S., & Rastegari, M. (2021). Mobilevit: light-weight, general-purpose, and mobile-friendly vision transformer. *arXiv:2110.02178*.
-   [8] Cai, W., et al. (2023). Lifelong anomaly detection via rehearsal-aided pseudo-residual learning. *arXiv:2306.04195*.
-   [9] Zhang, Z., Liu, Z., Loy, C. C., & Lin, D. (2019). Cross-view action recognition via viewpoint decomposition and recovery. *CVPR*.

---
