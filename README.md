# SecurityVision: Real-Time Video Anomaly Detection

## Overview

SecurityVision is an automated surveillance system designed for real-time video anomaly detection. [cite: 2, 3] It leverages advanced deep learning techniques, specifically utilizing I3D features combined with a modified Self-Supervised Sparse Representation (S3R) model, referred to as WatchTower. [cite: 3, 4] The system processes video input from CCTV cameras or uploaded files, identifies anomalous segments by detecting deviations from learned normal patterns, and presents alerts and visualizations through a web-based dashboard. [cite: 5, 9, 10] This project aims to address the need for automated systems capable of detecting unusual or threatening activities in the vast amount of video data generated by surveillance cameras. [cite: 7, 8]

## Features

-   **Real-time Anomaly Detection**: Utilizes the WatchTower (S3R-based) model trained on datasets like UCF-Crime to identify anomalies. [cite: 36]
-   **Live Video Monitoring**: Supports live video feeds with browser-based camera access.
-   **Toggle Surveillance**: Functionality to pause and resume monitoring.
-   **Visual and Audio Alerts**: Triggers alerts when anomalies are detected above a set threshold (e.g., 0.6). [cite: 47]
-   **Backward Timer Replay**: Allows review of the video segment leading up to a detected anomaly (e.g., 16 seconds prior). [cite: 48]
-   **Database Storage**: Saves detected anomalies with timestamps and confidence scores for future reference.
-   **Web-Based Interface**: An intuitive dashboard built with HTML, CSS (Bootstrap), and JavaScript for monitoring, visualization, and alert management. [cite: 11, 45]
-   **Anomaly Scoring**: Provides frame-wise ROC-AUC scores as a primary metric for evaluation. [cite: 39]

## Technology Stack

-   **Backend**: Python with Flask framework. [cite: 40]
-   **Machine Learning**: PyTorch for model implementation and inference (torch 1.6.0, torchvision), OpenCV for video processing. [cite: 41]
-   **Database**: PostgreSQL (or SQLite as a fallback).
-   **Frontend**: JavaScript, HTML5, Bootstrap. [cite: 45]
-   **Audio**: Tone.js for alert sounds.

## Theoretical Background

The anomaly detection core of this system is based on the **Self-Supervised Sparse Representation (S3R)** framework. [cite: 4, 19]
The S3R model operates on the principle of dictionary learning. It learns a dictionary of "normal" event patterns from a training dataset (e.g., normal videos from UCF-Crime). [cite: 27] Anomalies are then identified as events that cannot be sparsely reconstructed using this learned dictionary. [cite: 28]

Key components of the WatchTower (S3R based) model include:
-   **Feature Extraction**: Employs pre-trained Inflated 3D ConvNet (I3D) models (e.g., with ResNet-50 backbones) to extract robust spatiotemporal features (2048 dimensions) from video segments. [cite: 24, 25]
-   **Task-Specific Dictionary**: A dictionary learned from normal video features using Orthogonal Matching Pursuit (OMP). [cite: 29] The project uses a dictionary file like 'ucf-crime_dictionaries.taskaware.omp.100iters.50pct.npy'. [cite: 30]
-   **enNormal Module**: Reconstructs the normal component of an input feature snippet using the learned dictionary. [cite: 30]
-   **deNormal Module**: Aims to filter out normal components, potentially highlighting anomalous parts. [cite: 31]
-   **Anomaly Scoring**: Features are passed through embedding layers and classifiers to produce a final anomaly score. [cite: 32, 33]

The model checkpoint used is typically one like 'ucf-crime_s3r_i3d_best.pth', trained specifically for the UCF-Crime dataset using I3D features. [cite: 34]

## Project Structure
├── ml_models/            # Machine learning model implementations
│   ├── init.py
│   └── s3r_model.py      # S3R model implementation (WatchTower)
├── static/               # Static files (JS, CSS, images, sounds)
│   ├── css/
│   ├── js/
│   └── sounds/
├── templates/            # HTML templates
├── dictionary/           # Dictionary files for S3R model (e.g., ucf-crime_dictionaries.taskaware.omp.100iters.50pct.npy)
├── checkpoint/           # Model checkpoint files (e.g., ucf-crime_s3r_i3d_best.pth)
├── app.py                # Flask application setup
├── main.py               # Entry point for the application
├── ml_model.py           # ML model wrapper and anomaly detection logic
├── models.py             # Database models (SQLAlchemy)
├── routes.py             # Application routes
├── utils.py              # Utility functions
├── video_processor.py    # Video processing utilities
└── create_dictionary.py  # Script to create dictionary files (if applicable)

## Datasets

The system is designed to work with datasets like:
-   **UCF-Crime**: A large-scale dataset with long, untrimmed surveillance videos featuring 13 real-world anomalies (e.g., Fighting, Assault, Burglary) and normal activities. [cite: 36] Standard training/testing splits and I3D features provided with the S3R methodology are used. [cite: 37]

## Installation and Setup

1.  **Clone the repository**:
    ```bash
    git clone [https://github.com/kv-248/SecurityVision.git](https://github.com/kv-248/SecurityVision.git)
    cd SecurityVision
    ```
2.  **Create a Python virtual environment** (recommended):
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows use `venv\Scripts\activate`
    ```
3.  **Install dependencies**:
    The `requirements.txt` file lists primary dependencies. The original S3R model has its own `requirements.txt` as well.
    ```bash
    pip install -r requirements.txt
    # If using specific S3R functionalities, you might need to check S3R/requirements.txt
    ```
    Key dependencies include: Flask, SQLAlchemy, PyTorch, Torchvision, OpenCV-Python, NumPy. [cite: 40, 41, 44, 92]

4.  **Set up the Database**:
    -   The application can use PostgreSQL or fallback to SQLite.
    -   For PostgreSQL, ensure it's running, create a database, and set the `DATABASE_URL` environment variable.
    -   If `DATABASE_URL` is not set, it defaults to a local SQLite database (`surveillance.db`).
    ```bash
    # Example for setting DATABASE_URL (Linux/macOS)
    export DATABASE_URL="postgresql://user:password@host:port/database"
    ```
5.  **Download Pre-trained Models and Dictionaries**:
    -   Place the I3D model (e.g., `i3d_r50_kinetics.pth`) in an appropriate directory.
    -   Place the WatchTower/S3R checkpoint (e.g., `ucf-crime_s3r_i3d_best.pth`) in the `checkpoint/` directory. [cite: 43]
    -   Place the task-aware dictionary (e.g., `ucf-crime_dictionaries.taskaware.omp.100iters.50pct.npy`) in the `dictionary/` directory. [cite: 43]
    *(Links to these specific files might need to be provided or instructions on how to obtain them from the S3R repository)*

6.  **Run the application**:
    ```bash
    python main.py
    ```
    The application will be accessible at `http://localhost:5000` or `http://0.0.0.0:5000`.

## Usage

1.  **Navigate to the application** in your web browser.
2.  The **Home Page** provides an overview, system uptime, and statistics.
3.  Go to the **Surveillance Page** to start monitoring:
    * Allow camera access when prompted by the browser.
    * The video feed will start automatically.
    * Use "Toggle Surveillance" to pause/resume.
4.  **Anomaly Detection**:
    * The system processes video frames and flags anomalies.
    * Alerts (visual and audio) are triggered. [cite: 47]
    * A replay feature shows the segment leading to the alert. [cite: 48]
5.  **Alarm Controls**: Reset alarms as needed.
6.  **Confidence Scores**: Anomalies are reported with confidence scores. A typical detection threshold is 0.6, adjustable in `ml_model.py`. [cite: 47]
7.  **Frame Processing**: The system may process every Nth frame (e.g., 30th) for performance, adjustable in `ml_model.py`.

*(For more detailed usage, refer to USAGE.md)*

## Performance

-   The underlying S3R model with I3D features reports a frame-level AUC of **85.99%** on the UCF-Crime dataset. [cite: 51, 55] The WatchTower model aims to replicate or build upon this. [cite: 56]
-   Real-time performance is dependent on hardware (GPU acceleration is beneficial), feature extraction speed, and model inference time. [cite: 59, 63, 64]

## Compute Requirements

-   **Training**: Requires GPUs (e.g., NVIDIA RTX series like RTX 2080 Ti) with sufficient memory, especially for large datasets. [cite: 62] CUDA 10.1 was used in the reference S3R implementation. [cite: 44, 64]
-   **Inference**: GPU acceleration is highly recommended for real-time performance. CPU inference is possible but significantly slower. [cite: 64, 65]
-   **Memory/Storage**: Adequate RAM and fast storage (SSDs) are needed for video streams and features. [cite: 66]
-   **Software Environment**: Python (3.6 tested for S3R, project report mentions 3.6 [cite: 67]), PyTorch (1.6.0 tested [cite: 41, 67]).

## Future Work

Based on the "SecurityVision" project report[cite: 71]:
1.  **Explore more efficient feature extractors**: Alternatives to the computationally heavy I3D, such as MobileViT[cite: 72], could improve performance/cost trade-offs, especially for edge devices.
2.  **Implement online learning**: Allow the model to adapt to specific deployment environments and evolving normal patterns over time by moving from an offline dictionary to online/continual learning approaches. [cite: 73]
3.  **Multi-camera support**: Utilize synchronized feeds from multiple cameras using multi-view learning techniques to provide richer context, handle occlusions better, and increase detection robustness. [cite: 74]

## License

This project is licensed under the MIT License. (Assuming, based on common practice and `New folder/README.md`. Please confirm and add a LICENSE file if true.)

## Acknowledgments

-   The S3R model architecture and methodology by Jhih-Ciang Wu, He-Yen Hsieh, Ding-Jie Chen, Chiou-Shann Fuh, and Tyng-Luh Liu. [cite: 81] (Paper: "Self-Supervised Sparse Representation for Video Anomaly Detection", ECCV 2022).
-   The original S3R implementation is acknowledged as a base for some code aspects.
-   UCF-Crime dataset by the University of Central Florida.
-   I3D model by Carreira and Zisserman. [cite: 77]

## References

-   [1] Carreira, J., & Zisserman, A. (2017). Quo vadis, action recognition? a new model and the kinetics dataset. *CVPR*. [cite: 77, 78]
-   [2] Sultani, W., Chen, C., & Shah, M. (2018). Real-world anomaly detection in surveillance videos. *CVPR*. [cite: 79]
-   [3] Wang, S., Li, B. Z., Khabsa, M., Fang, H., & Ma, H. (2020). Linformer: Self-attention with linear complexity. *arXiv:2006.04768*. [cite: 80]
-   [4] Wu, J. C., Hsieh, H. Y., Chen, D. J., Fuh, C. S., & Liu, T. L. (2022). Self-Supervised Sparse Representation for Video Anomaly Detection. *ECCV*. [cite: 81]
-   [6] Feichtenhofer, C., Fan, H., Malik, J., & He, K. (2019). Slowfast networks for video recognition. *ICCV*. [cite: 84]
-   [7] Mehta, S., & Rastegari, M. (2021). Mobilevit: light-weight, general-purpose, and mobile-friendly vision transformer. *arXiv:2110.02178*. [cite: 85]
-   [8] Cai, W., et al. (2023). Lifelong anomaly detection via rehearsal-aided pseudo-residual learning. *arXiv:2306.04195*. [cite: 86, 87]
-   [9] Zhang, Z., Liu, Z., Loy, C. C., & Lin, D. (2019). Cross-view action recognition via viewpoint decomposition and recovery. *CVPR*. [cite: 88]

---
